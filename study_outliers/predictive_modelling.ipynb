{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive modelling\n",
    "Author: Dr. Marco Zanin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def data_preparation(dataset, numeric_features, binary_features,\n",
    "                     categorical_features, target, outliers_ids):\n",
    "    \"\"\"\n",
    "        This function processes the input data.\n",
    "    \"\"\"\n",
    "    ## Handling date\n",
    "    # 1. converts date to datetime\n",
    "    dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "    # 2. converts datetime to numeric value\n",
    "    dataset['date_numeric'] = dataset['date'].map(\n",
    "        {date: idx for idx, date in enumerate(dataset['date'].unique())}\n",
    "    )\n",
    "    # 3. drops the original date column\n",
    "    dataset = dataset.drop(columns=['date'])\n",
    "\n",
    "    ## Check which columns exist in the dataset for each feature type\n",
    "    numeric_features = [col for col in numeric_features if col in dataset.columns]\n",
    "    binary_features = [col for col in binary_features if col in dataset.columns]\n",
    "    categorical_features = [col for col in categorical_features if col in dataset.columns]\n",
    "\n",
    "    ## Convert categorical features to 'category' dtype\n",
    "    dataset[categorical_features] = dataset[categorical_features].astype('category')\n",
    "\n",
    "    ## Process numeric features (standardize them)\n",
    "    if numeric_features:\n",
    "        scaler = StandardScaler()\n",
    "        numeric_data_scaled = pd.DataFrame(scaler.fit_transform(dataset[numeric_features]), \n",
    "                                           columns=numeric_features, index=dataset.index)\n",
    "    else:\n",
    "        numeric_data_scaled = pd.DataFrame(index=dataset.index)  # Empty DataFrame if no numeric features\n",
    "\n",
    "    ## Process binary features (leave them unchanged)\n",
    "    binary_data = dataset[binary_features] if binary_features else pd.DataFrame(index=dataset.index)\n",
    "\n",
    "    ## Process categorical features (one-hot encode them)\n",
    "    if categorical_features:\n",
    "        categorical_data_encoded = pd.get_dummies(dataset[categorical_features], drop_first=False)\n",
    "    else:\n",
    "        categorical_data_encoded = pd.DataFrame(index=dataset.index)\n",
    "\n",
    "    ## Combine numeric, binary, and categorical data\n",
    "    dataset_processed = pd.concat([numeric_data_scaled, binary_data, categorical_data_encoded], axis=1)\n",
    "\n",
    "    ## Remove the outliers\n",
    "    # Select all rows except those with the specified indices\n",
    "    dataset_no_outliers = dataset.loc[~dataset.index.isin(outliers_ids)]\n",
    "    dataset_processed_no_outliers = dataset_processed.loc[~dataset_processed.index.isin(outliers_ids)]\n",
    "\n",
    "    ## Create datasets for models\n",
    "    # with outliers\n",
    "    X_full = dataset_processed\n",
    "    y_full = dataset[target]\n",
    "    # without outliers\n",
    "    X_no_outliers = dataset_processed_no_outliers\n",
    "    y_no_outliers = dataset_no_outliers[target]\n",
    "\n",
    "    return X_full, y_full, X_no_outliers, y_no_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "\n",
    "backs_vssg = pd.read_csv(\"./data/backs_vssg_study.csv\")\n",
    "\n",
    "forwards_vssg = pd.read_csv(\"./data/forwards_vssg_study.csv\")\n",
    "\n",
    "ssg = pd.read_csv(\"./data/ssg_study.csv\")\n",
    "\n",
    "# Create a column to differentiate between forwards and backs\n",
    "ssg['forward0_back1'] = ssg['players'].apply(lambda x: 0 if x <= 22 else 1)\n",
    "# Convert the new column to integer\n",
    "ssg['forward0_back1'] = ssg['forward0_back1'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers identified for each data frame\n",
    "outlier_ids_backs = [97, 230, 248, 40, 264, 304, 430, 28, 178, 16, 4, 444, 157, 321, 355, 174, 372, 444]\n",
    "outlier_ids_forwards = [179,238,265,299,319,339,502]\n",
    "outlier_ids_ssg = [4,6,36,105,142,222,223,254,258,411,420,447,463,499,553,587,621,636,655]\n",
    "\n",
    "# inputs\n",
    "numeric_features = [ 'total_distance_m', 'tot_hsr_distance',\n",
    "       'acceleration_density', 'total_player_load', 'player_load_slow',\n",
    "       'get_up', 'bullet']\n",
    "binary_features = ['forward0_back1']\n",
    "categorical_features = ['players', 'date_numeric', 'ssg_bout']\n",
    "target = 'stagnos_trimp'\n",
    "\n",
    "\n",
    "# dataset for model training\n",
    "X_full, y_full, X_no_outliers, y_no_outliers = data_preparation(ssg,\n",
    "                                                                numeric_features,\n",
    "                                                                binary_features,\n",
    "                                                                categorical_features,\n",
    "                                                                target,\n",
    "                                                                outlier_ids_ssg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'KNearestNeighbors': KNeighborsRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=RANDOM_STATE),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=RANDOM_STATE),\n",
    "}\n",
    "\n",
    "# Define the 10-fold cross-validation for consistency across models\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "# Create an empty DataFrame to store the scores\n",
    "scores_df_full = pd.DataFrame()\n",
    "scores_df_no_outliers = pd.DataFrame()\n",
    "\n",
    "# Evaluate each model using 10-fold cross-validation and store the individual scores\n",
    "for name, model in models.items():\n",
    "    scores_full = -cross_val_score(model, X_full, y_full, scoring=\"neg_root_mean_squared_error\", cv=kf)\n",
    "    scores_no_outliers = -cross_val_score(model, X_no_outliers, y_no_outliers, scoring=\"neg_root_mean_squared_error\", cv=kf)\n",
    "    \n",
    "    # Create a DataFrame for the individual scores and add a column for the model name\n",
    "    model_scores_df_full = pd.DataFrame(scores_full, columns=[name])\n",
    "    model_scores_no_outliers = pd.DataFrame(scores_no_outliers, columns=[name])\n",
    "    \n",
    "    # Concatenate the individual scores with the scores_df\n",
    "    scores_df_full = pd.concat([scores_df_full, model_scores_df_full], axis=1)\n",
    "    scores_df_no_outliers = pd.concat([scores_df_no_outliers, model_scores_no_outliers], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>128.660855</td>\n",
       "      <td>27.079357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>134.418796</td>\n",
       "      <td>27.955652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>135.744724</td>\n",
       "      <td>31.149857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNearestNeighbors</th>\n",
       "      <td>158.297595</td>\n",
       "      <td>28.228378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Mean  Standard Deviation\n",
       "Gradient Boosting  128.660855           27.079357\n",
       "Random Forest      134.418796           27.955652\n",
       "Linear Regression  135.744724           31.149857\n",
       "KNearestNeighbors  158.297595           28.228378"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FULL DATA: Calculating mean and standard deviation for each column\n",
    "mean_std_df_full = pd.DataFrame({\n",
    "    'Mean': scores_df_full.mean(axis=0),\n",
    "    'Standard Deviation': scores_df_full.std(axis=0)\n",
    "}).sort_values('Mean')\n",
    "mean_std_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>100.086468</td>\n",
       "      <td>9.537541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>101.194564</td>\n",
       "      <td>10.294196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>107.323823</td>\n",
       "      <td>7.983176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNearestNeighbors</th>\n",
       "      <td>123.734664</td>\n",
       "      <td>10.865306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Mean  Standard Deviation\n",
       "Gradient Boosting  100.086468            9.537541\n",
       "Linear Regression  101.194564           10.294196\n",
       "Random Forest      107.323823            7.983176\n",
       "KNearestNeighbors  123.734664           10.865306"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NO OUTLIERS: Calculating mean and standard deviation for each column\n",
    "mean_std_df_no_outliers = pd.DataFrame({\n",
    "    'Mean': scores_df_no_outliers.mean(axis=0),\n",
    "    'Standard Deviation': scores_df_no_outliers.std(axis=0)\n",
    "}).sort_values('Mean')\n",
    "mean_std_df_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TtestResult(statistic=2.976403382745041, pvalue=0.015540035301557426, df=9)\n",
      "ConfidenceInterval(low=8.290986740599372, high=60.8093327007113)\n"
     ]
    }
   ],
   "source": [
    "## Statistical comparison: paired samples t-test\n",
    "\n",
    "# model name\n",
    "my_model_name = 'Linear Regression'\n",
    "\n",
    "# filter data\n",
    "model_array_scores_full = scores_df_full[my_model_name]\n",
    "model_array_scores_no_outliers = scores_df_no_outliers[my_model_name]\n",
    "\n",
    "# run test\n",
    "res = stats.ttest_rel(model_array_scores_full,model_array_scores_no_outliers)\n",
    "print(res)\n",
    "print(res.confidence_interval(confidence_level=0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
